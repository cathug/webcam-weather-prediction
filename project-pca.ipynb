{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, glob\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.transform import rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_path =r'/home/garfield/Desktop/cmpt318/project/yvr-weather'\n",
    "image_path =r'/home/garfield/Desktop/cmpt318/project/katkam-scaled'\n",
    "reg_pattern = 'katkam\\W([\\d]+)'\n",
    "\n",
    "def printValueCountsInEachColumn(df):\n",
    "    headers = list(df)\n",
    "    for header in headers:\n",
    "        print(header + \"\\n\")\n",
    "        print(str(df[header].value_counts().index) + \"\\n\\n\")\n",
    "        \n",
    "\n",
    "def extract_date(path):\n",
    "    match_reg_pattern = re.search(reg_pattern, path)\n",
    "    if match_reg_pattern:\n",
    "        return match_reg_pattern.group(1)\n",
    "\n",
    "    \n",
    "def extract_filename(path):\n",
    "    match_reg_pattern = re.search(reg_pattern + '.jpg', path)\n",
    "    if match_reg_pattern:\n",
    "        return match_reg_pattern.group(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following two functions are adapted from \n",
    "# http://blog.yhat.com/posts/image-processing-with-scikit-image.html\n",
    "def display_image(images_rgb):\n",
    "#    plt.clf()\n",
    "    plt.figure()\n",
    "    \n",
    "    i = 0\n",
    "    for image in images_rgb:\n",
    "        plt.subplot(1, len(images_rgb), i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)\n",
    "        i = i + 1\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def separate_image_layers(image_rgb):\n",
    "    image_r, image_g, image_b = image_rgb.copy(), image_rgb.copy(), image_rgb.copy()\n",
    "    # switch off other color layers to show isolated r, g, b layers\n",
    "    image_r[:,:,(1,2)] = 0\n",
    "    image_g[:,:,(0,2)] = 0\n",
    "    image_b[:,:,(0,1)] = 0\n",
    "    \n",
    "    return image_r, image_g, image_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_image0(imagepath):\n",
    "    image = io.imread(imagepath)\n",
    "    image_r, image_g, _ = separate_image_layers(image)\n",
    "    #image_r, image_g, image_b = separate_image_layers(image)\n",
    "    #average = np.average([image_r, image_g, image_b])\n",
    "    average = np.average([image_r, image_g])\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_image1(imagepath):\n",
    "    image = io.imread(imagepath)\n",
    "    #image_r, _, _ = separate_image_layers(image)\n",
    "    #image_r, image_g, image_b = separate_image_layers(image)\n",
    "    #average = np.average([image_r, image_g, image_b])\n",
    "    #average = np.average([image_r, image_g])\n",
    "    image_rescaled = rescale(image, 0.25, mode='reflect') # 1/4 scale to overcome memory issues\n",
    "    output = image_rescaled.reshape(1, -1) # reshape to (147456, 1)\n",
    "    return np.squeeze(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function divides the image to random patches and takes the average value \n",
    "def add_image2(imagepath):\n",
    "    image = io.imread(imagepath)\n",
    "    patches = extract_patches_2d(image, (24, 32), max_patches=8, random_state=np.random.RandomState(0))\n",
    "    average = np.average(patches)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this crops out the sky and takes average\n",
    "def add_image3(imagepath):\n",
    "    image = io.imread(imagepath)\n",
    "    sky = image[:48,:256,:]\n",
    "    average = np.average(sky)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this crops out the sky, tree, road, sea sections and takes average\n",
    "def add_image4(imagepath):\n",
    "    image = io.imread(imagepath)\n",
    "    sky = image[:96,:256,:]\n",
    "    sky_patches = extract_patches_2d(sky, (12, 16), \n",
    "        max_patches=8, random_state=np.random.RandomState(0))\n",
    "    road = image[150:,:50,:]\n",
    "    trees = image[144:175,210:,:]\n",
    "    sea = image[125:,100:200,:]\n",
    "#    bottom = image[96:, 128:, :]\n",
    "    \n",
    "    average1 = np.average(sky_patches)\n",
    "    #average1 = np.average(sky)\n",
    "    average2 = np.average(trees)\n",
    "    average3 = np.average(road)\n",
    "    average4 = np.average(sea)\n",
    "    #total = average1 + average2 + average3 + average4\n",
    "    #return total\n",
    "    return average1, average2, average3, average4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "image2 = image_path + r'/katkam-20160605100000.jpg'\n",
    "i = io.imread(image2)\n",
    "i2 = i.reshape(1, -1) # reshape to (147456, 1)\n",
    "\n",
    "np.squeeze(i2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trees = i[125:,100:200,:]\n",
    "trees.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y = trees.shape[0]\n",
    "x = trees.shape[1]\n",
    "h = 8\n",
    "w = (y/x) * h\n",
    "plt.figure(figsize=(w,h))\n",
    "plt.imshow(trees, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove certainty items in weather column\n",
    "def clean_description(stringlist):            \n",
    "    contains = 'Heavy|Moderate|Mostly|Mainly|Showers|Pellets|Fog|Freezing|nan'\n",
    "    \n",
    "    # remove matching words in list    \n",
    "    for word in stringlist:        \n",
    "        match = re.match(contains, word)\n",
    "        if match:\n",
    "            stringlist.remove(word)\n",
    "        \n",
    "    # remove repetition or if string contains \"Fog\"\n",
    "    while len(stringlist) > 0:\n",
    "        if ( (len(stringlist) > 1) and (stringlist[0] == stringlist[-1]) ) or (stringlist[-1] == 'Fog'):\n",
    "            stringlist.remove(stringlist[-1])\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    output = ','.join(stringlist)\n",
    "    if output == \"\":\n",
    "        return None\n",
    "#    elif output == 'Rain,Snow':\n",
    "#        return 'Rain'\n",
    "#    elif output == 'Thunderstorms':\n",
    "#        return 'Rain'\n",
    "    \n",
    "    # else\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv files import\n",
    "csv_files = glob.glob(csv_path + '/*.csv')\n",
    "dataframes = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    table = pd.read_csv(csv_file, sep=',', \n",
    "                        skiprows=16, parse_dates=[0])\n",
    "    dataframes.append(table)\n",
    "df = pd.concat(dataframes)\n",
    "#printValueCountsInEachColumn(df)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image files import\n",
    "image_files = glob.glob(image_path + '/*.jpg')\n",
    "image_df = pd.DataFrame({'path' : image_files})\n",
    "image_df['filename'] = image_df['path'].apply(extract_filename)\n",
    "\n",
    "image_df['Date/Time'] = pd.to_datetime(\n",
    "    image_df['path'].apply(extract_date),\n",
    "    infer_datetime_format=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image values and remove unnecessary crap\n",
    "image_df['image'] = image_df['path'].apply(add_image1)\n",
    "image_vals = image_df['image'].apply(pd.Series)\n",
    "image_df.drop(labels=['path', 'filename', 'image'], axis=1, inplace=True)\n",
    "image_vals = image_df.merge(image_vals, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove NaN columns and columns consisting mostly of NaN\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "df = df.select(lambda x: not re.search('Quality|Chill|Hmdx', x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change column names\n",
    "df.columns = ['Date/Time', 'year', 'month', 'day', 'hour',\n",
    "              'temp', 'dew_temp', 'rel_hum', 'wind_dir',\n",
    "              'wind_speed', 'visibility', 'pressure', 'weather']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge dataframes df and image_vals\n",
    "df = image_vals.merge(df, how='left', on='Date/Time')\n",
    "df.drop(labels=['Date/Time'], axis=1, inplace=True)\n",
    "df['hour'] = pd.to_datetime(df['hour'], format='%H:%M').dt.hour # keep hour only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean weather labeling\n",
    "df['weather'] = df['weather'].astype('str')  # cast weather descriptions as strings\n",
    "df['weather'].replace(to_replace='Drizzle',\n",
    "    value='Rain', inplace=True, regex=True)\n",
    "\n",
    "df['weather'] = df['weather'].str.split(pat=' |,')\n",
    "df['weather'] = df['weather'].apply(clean_description)\n",
    "\n",
    "#df['weather'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select rows without null values\n",
    "weather_described = df.dropna(axis=0, how='any') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create machine learning sets\n",
    "X = weather_described.drop(labels=['weather'], axis=1)\n",
    "y = weather_described['weather']\n",
    "\n",
    "# reduce dimensions\n",
    "pca = PCA(20)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.749103942652\n"
     ]
    }
   ],
   "source": [
    "bayes = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    GaussianNB()\n",
    ")\n",
    "\n",
    "bayes.fit(X_train, y_train)\n",
    "print(bayes.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772401433692\n"
     ]
    }
   ],
   "source": [
    "svc = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVC(kernel='rbf', C=5)\n",
    "    )\n",
    "svc.fit(X_train, y_train)\n",
    "print(svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.713261648746\n"
     ]
    }
   ],
   "source": [
    "k_neighbour = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KNeighborsClassifier(n_neighbors=8)\n",
    ")\n",
    "\n",
    "k_neighbour.fit(X_train, y_train)\n",
    "print(k_neighbour.score(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
