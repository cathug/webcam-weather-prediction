{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, glob\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_path =r'/home/garfield/Desktop/cmpt318/project/yvr-weather'\n",
    "image_path =r'/home/garfield/Desktop/cmpt318/project/katkam-scaled'\n",
    "reg_pattern = 'katkam\\W([\\d]+)'\n",
    "\n",
    "def printValueCountsInEachColumn(df):\n",
    "    headers = list(df)\n",
    "    for header in headers:\n",
    "        print(header + \"\\n\")\n",
    "        print(str(df[header].value_counts().index) + \"\\n\\n\")\n",
    "        \n",
    "\n",
    "def extract_date(path):\n",
    "    match_reg_pattern = re.search(reg_pattern, path)\n",
    "    if match_reg_pattern:\n",
    "        return match_reg_pattern.group(1)\n",
    "\n",
    "    \n",
    "def extract_filename(path):\n",
    "    match_reg_pattern = re.search(reg_pattern + '.jpg', path)\n",
    "    if match_reg_pattern:\n",
    "        return match_reg_pattern.group(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_image(imagepath):\n",
    "    image = io.imread(imagepath)\n",
    "    #titles = \"red layer\", \"green layer\", \"blue layer\"\n",
    "    image_r, image_g, _ = separate_image_layers(image)\n",
    "    #display_image(image_rgb_layers,titles)\n",
    "    average = np.average([image_r, image_g])\n",
    "    #return image_r\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following two functions are adapted from \n",
    "# http://blog.yhat.com/posts/image-processing-with-scikit-image.html\n",
    "def display_image(images_rgb, titles):\n",
    "#    plt.clf()\n",
    "    plt.figure()\n",
    "    \n",
    "    i = 0\n",
    "    for image, title in zip(images_rgb, titles):\n",
    "        plt.subplot(1, len(images_rgb), i + 1)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)\n",
    "        i = i + 1\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def separate_image_layers(image_rgb):\n",
    "    image_r, image_g, image_b = image_rgb.copy(), image_rgb.copy(), image_rgb.copy()\n",
    "    # switch off other color layers to show isolated r, g, b layers\n",
    "    image_r[:,:,(1,2)] = 0\n",
    "    image_g[:,:,(0,2)] = 0\n",
    "    image_b[:,:,(0,1)] = 0\n",
    "    \n",
    "    return image_r, image_g, image_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_files = glob.glob(csv_path + '/*.csv')\n",
    "dataframes = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    table = pd.read_csv(csv_file, sep=',', \n",
    "                        skiprows=16, parse_dates=[0])\n",
    "    dataframes.append(table)\n",
    "df = pd.concat(dataframes)\n",
    "#printValueCountsInEachColumn(df)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_files = glob.glob(image_path + '/*.jpg')\n",
    "image_df = pd.DataFrame({'path' : image_files})\n",
    "image_df['filename'] = image_df['path'].apply(extract_filename)\n",
    "\n",
    "image_df['Date/Time'] = pd.to_datetime(\n",
    "    image_df['path'].apply(extract_date),\n",
    "    infer_datetime_format=True\n",
    ")\n",
    "\n",
    "#image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.select(lambda x: not re.search('Quality|^(Year|Month|Day|Time)|Chill|Hmdx', x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean data in dataframe\n",
    "def cleanData(df):\n",
    "    # change column names\n",
    "    df.columns = ['path', 'filename', 'date', 'temp', 'dew_temp', \n",
    "                  'rel_hum', 'wind_dir','wind_speed',\n",
    "                  'visibility','pressure','weather']\n",
    "    \n",
    "    # cast weather descriptions as strings\n",
    "    df['weather'] = df['weather'].astype('str') \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = image_df.merge(df, how='left', on='Date/Time')\n",
    "df = cleanData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove certainty items in weather column\n",
    "def clean_description(string):    \n",
    "    string = string.replace('Drizzle', 'Rain')\n",
    "    \n",
    "    remove_words = ['Heavy','Moderate','Mostly','Mainly',\n",
    "        'Showers','Pellets','Fog','Freezing','nan']\n",
    "    \n",
    "    for i in range(2):\n",
    "        if i == 1:\n",
    "            words = string.replace(' ', ',').split(sep=',')\n",
    "\n",
    "        else:\n",
    "            words = string.split(sep=',')\n",
    "            \n",
    "    \n",
    "        for word in words:        \n",
    "            for r in remove_words:\n",
    "                if word == r:\n",
    "                    words.remove(r)\n",
    "\n",
    "        if len(words) > 1 and (words[0] == words[1]):\n",
    "            words.remove(words[1])\n",
    "        string = ','.join(words)\n",
    "    \n",
    "    if string == \"\" or string =='Fog':\n",
    "        return None\n",
    "    else:\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(clean_description(df['weather'].iloc[0]))\n",
    "#print(len(clean_description(df['weather'].iloc[5039])))\n",
    "\n",
    "#df['weather'].iloc[5039]\n",
    "#df['weather']\n",
    "df['weather'] = df['weather'].apply(clean_description)\n",
    "#df['weather'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.isnull(df).sum() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df\n",
    "#df['weather'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select rows without null values\n",
    "weather_described = df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/garfield/.local/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "weather_described['image'] = weather_described['path'].apply(add_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#weather_described['date'].dt.time.value_counts().index\n",
    "#weather_described['date'].dt.month.value_counts().index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = weather_described.drop(labels=['filename', 'path', 'weather'], axis=1)\n",
    "\n",
    "#s = add_image(X['path'].iloc[10])\n",
    "#print(\"The height of s is \" + str(len(s)))\n",
    "#print(\"The width of s is \" + str(len(s[0])))\n",
    "\n",
    "#print(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.drop(['date'], axis=1, inplace=True)\n",
    "\n",
    "y = weather_described['weather']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.672043010753\n"
     ]
    }
   ],
   "source": [
    "bayes = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    GaussianNB()\n",
    ")\n",
    "\n",
    "bayes.fit(X_train, y_train)\n",
    "print(bayes.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.720430107527\n"
     ]
    }
   ],
   "source": [
    "svc = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVC(kernel='rbf', C=10)\n",
    "    )\n",
    "svc.fit(X_train, y_train)\n",
    "print(svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70788530465949817"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_neighbour = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KNeighborsClassifier(n_neighbors=5)\n",
    ")\n",
    "\n",
    "k_neighbour.fit(X_train, y_train)\n",
    "k_neighbour.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
