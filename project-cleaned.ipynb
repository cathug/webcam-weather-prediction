{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, glob\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.image import extract_patches_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_path =r'/home/garfield/Desktop/cmpt318/project/yvr-weather'\n",
    "image_path =r'/home/garfield/Desktop/cmpt318/project/katkam-scaled'\n",
    "reg_pattern = 'katkam\\W([\\d]+)'\n",
    "\n",
    "def printValueCountsInEachColumn(df):\n",
    "    headers = list(df)\n",
    "    for header in headers:\n",
    "        print(header + \"\\n\")\n",
    "        print(str(df[header].value_counts().index) + \"\\n\\n\")\n",
    "        \n",
    "\n",
    "def extract_date(path):\n",
    "    match_reg_pattern = re.search(reg_pattern, path)\n",
    "    if match_reg_pattern:\n",
    "        return match_reg_pattern.group(1)\n",
    "\n",
    "    \n",
    "def extract_filename(path):\n",
    "    match_reg_pattern = re.search(reg_pattern + '.jpg', path)\n",
    "    if match_reg_pattern:\n",
    "        return match_reg_pattern.group(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following two functions are adapted from \n",
    "# http://blog.yhat.com/posts/image-processing-with-scikit-image.html\n",
    "def display_image(images_rgb):\n",
    "#    plt.clf()\n",
    "    plt.figure()\n",
    "    \n",
    "    i = 0\n",
    "    for image in images_rgb:\n",
    "        plt.subplot(1, len(images_rgb), i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)\n",
    "        i = i + 1\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def separate_image_layers(image_rgb):\n",
    "    image_r, image_g, image_b = image_rgb.copy(), image_rgb.copy(), image_rgb.copy()\n",
    "    # switch off other color layers to show isolated r, g, b layers\n",
    "    image_r[:,:,(1,2)] = 0\n",
    "    image_g[:,:,(0,2)] = 0\n",
    "    image_b[:,:,(0,1)] = 0\n",
    "    \n",
    "    return image_r, image_g, image_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_image(imagepath):\n",
    "    image = io.imread(imagepath)\n",
    "    image_r, image_g, _ = separate_image_layers(image)\n",
    "    average = np.average([image_r, image_g])\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function divides the image to random patches and takes the average value \n",
    "def add_image2(imagepath):\n",
    "    image = io.imread(imagepath)\n",
    "    patches = extract_patches_2d(image, (24, 32), max_patches=8, random_state=np.random.RandomState(0))\n",
    "    average = np.average(patches)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this crops out the sky and takes average\n",
    "def add_image3(imagepath):\n",
    "    image = io.imread(imagepath)\n",
    "    sky = image[:48,:256,:]\n",
    "    average = np.average(sky)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this crops out the sky and takes average\n",
    "def add_image4(imagepath):\n",
    "    image = io.imread(imagepath)\n",
    "    sky = image[:96,:256,:]\n",
    "    patches = extract_patches_2d(sky, (12, 16), \n",
    "        max_patches=8, random_state=np.random.RandomState(0))\n",
    "    road = image[150:,:50,:]\n",
    "    trees = image[144:175,210:,:]\n",
    "    sea = image[125:,100:200,:]\n",
    "#    bottom = image[96:, 128:, :]\n",
    "    \n",
    "    average1 = np.average(patches)\n",
    "    average2 = np.average(trees)\n",
    "    average3 = np.average(road)\n",
    "    average4 = np.average(sea)\n",
    "    total = average1 + average2 + average3 + average4\n",
    "    return total"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "image = image_path + r'/katkam-20160605100000.jpg'\n",
    "i = io.imread(image)\n",
    "i.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trees = i[125:,100:200,:]\n",
    "trees.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y = trees.shape[0]\n",
    "x = trees.shape[1]\n",
    "h = 8\n",
    "w = (y/x) * h\n",
    "plt.figure(figsize=(w,h))\n",
    "plt.imshow(trees, interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove certainty items in weather column\n",
    "def clean_description(string):    \n",
    "    string = string.replace('Drizzle', 'Rain')\n",
    "    \n",
    "    remove_words = ['Heavy','Moderate','Mostly','Mainly',\n",
    "        'Showers','Pellets','Fog','Freezing','nan']\n",
    "    \n",
    "    for i in range(2):\n",
    "        if i == 1:\n",
    "            words = string.replace(' ', ',').split(sep=',')\n",
    "\n",
    "        else:\n",
    "            words = string.split(sep=',')\n",
    "            \n",
    "    \n",
    "        for word in words:        \n",
    "            for r in remove_words:\n",
    "                if word == r:\n",
    "                    words.remove(r)\n",
    "\n",
    "        if len(words) > 1 and (words[0] == words[1]):\n",
    "            words.remove(words[1])\n",
    "        string = ','.join(words)\n",
    "    \n",
    "    if string == \"\" or string =='Fog':\n",
    "        return None\n",
    "    else:\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_files = glob.glob(csv_path + '/*.csv')\n",
    "dataframes = []\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    table = pd.read_csv(csv_file, sep=',', \n",
    "                        skiprows=16, parse_dates=[0])\n",
    "    dataframes.append(table)\n",
    "df = pd.concat(dataframes)\n",
    "#printValueCountsInEachColumn(df)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = glob.glob(image_path + '/*.jpg')\n",
    "image_df = pd.DataFrame({'path' : image_files})\n",
    "image_df['filename'] = image_df['path'].apply(extract_filename)\n",
    "\n",
    "image_df['Date/Time'] = pd.to_datetime(\n",
    "    image_df['path'].apply(extract_date),\n",
    "    infer_datetime_format=True\n",
    ")\n",
    "\n",
    "image_df['image'] = image_df['path'].apply(add_image3)\n",
    "\n",
    "#image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean data\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "df = df.select(lambda x: not re.search('Quality|Chill|Hmdx', x), axis=1)\n",
    "df = image_df[['Date/Time', 'image']].merge(df, how='left', on='Date/Time')\n",
    "df.drop(labels=['Date/Time'], axis=1, inplace=True)\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M').dt.hour # keep hour only\n",
    "\n",
    "# change column names\n",
    "df.columns = ['image', 'year', 'month', 'day', 'hour',\n",
    "              'temp', 'dew_temp', 'rel_hum', 'wind_dir',\n",
    "              'wind_speed', 'visibility', 'pressure', 'weather']\n",
    "\n",
    "# cast weather descriptions as strings\n",
    "df['weather'] = df['weather'].astype('str') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['weather'] = df['weather'].apply(clean_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_described = df.dropna(axis=0, how='any') #select rows without null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create machine learning sets\n",
    "X = weather_described[['image', 'month', 'hour', 'temp',\n",
    "                       'dew_temp','rel_hum','wind_dir',\n",
    "                       'wind_speed','visibility','pressure']]\n",
    "y = weather_described['weather']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.709677419355\n"
     ]
    }
   ],
   "source": [
    "bayes = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    GaussianNB()\n",
    ")\n",
    "\n",
    "bayes.fit(X_train, y_train)\n",
    "print(bayes.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752688172043\n"
     ]
    }
   ],
   "source": [
    "svc = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVC(kernel='rbf', C=5)\n",
    "    )\n",
    "svc.fit(X_train, y_train)\n",
    "print(svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75268817204301075"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_neighbour = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KNeighborsClassifier(n_neighbors=5)\n",
    ")\n",
    "\n",
    "k_neighbour.fit(X_train, y_train)\n",
    "k_neighbour.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
